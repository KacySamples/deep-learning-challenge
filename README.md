# deep-learning-challenge
Module21Challenge


## Summary

1: Installed TensorFlow using (pip install TensorFlow)

2: Data Preprocessing:

a. Loaded a dataset (charity_data.csv) into a pandas DataFrame and displayed its first few rows.

b. Dropped non-beneficial ID columns (EIN and NAME) from the DataFrame.

c. Determined the number of unique values in each column to identify categorical variables for encoding.

d. Examined the APPLICATION_TYPE and CLASSIFICATION columns for value counts to identify values for binning.

e. Binned rare values in APPLICATION_TYPE and CLASSIFICATION into an "Other" category based on a chosen cutoff value.

f. Converted categorical variables into numeric features using pd.get_dummies().

3. Splitting Data:

a. Split the preprocessed data into feature (X) and target (y) arrays, assuming a target variable (e.g., IS_SUCCESSFUL).

b. Further split the data into training and testing sets using train_test_split.

4. Model Creation and Compilation:

a. Defined a sequential neural network model with TensorFlow/Keras, specifying the number of input features, hidden nodes for each layer, and the activation functions.

b. Compiled the model with an optimizer (adam), a loss function (binary_crossentropy), and metrics (accuracy).

5. Model Training:

a. Trained the model on the training data, specifying the number of epochs, batch size, and validation split.

b. Addressed a potential ValueError related to data type conversion by ensuring all input data is converted to float32.

6. Model Saving:

a. Exported the trained model to an HDF5 file using the save method for future use.


## Credits
For this challenge, I utilized Google, ChatGPT, Stack Overflow, TA assistance, and educational resources related to the unit provided by BCS.

## License
Data for this dataset was generated by edX Boot Camps LLC and is intended for educational purposes only.
